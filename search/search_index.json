{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"About","text":"<p>After a lot of thinking, following the example of @niqdev, I made up my mind to create this project to collect all the useful information about what I like most: programming.</p> <p>This is still a collection of what I think might be useful resources for inspiring new and old developers. I chose to release it under the GNU General Public License v3.0, because I honestly consider it one of the most powerful resource to help the community, giving to each other the Freedom to improve and share knowledge.</p> <p>For this very reason, I invite you to give your free contribution to this collection of documents. They will be always accessible and they will be Free/Libre.</p>"},{"location":"#why-doing-this","title":"Why doing this?","text":"<p>Most of all because writing good software is hard, and doing it without organizing and keeping track of what you find useful is the act of a fool. I love to think our brains in the same way as Conan Doyle originally described it:</p> <p>Quote</p> <p>\u201cI consider that a man's brain originally is like a little empty attic, and you have to stock it with such furniture as you choose. A fool takes in all the lumber of every sort that he comes across, so that the knowledge which might be useful to him gets crowded out, or at best is jumbled up with a lot of other things, so that he has a difficulty in laying his hands upon it. Now the skillful workman is very careful indeed as to what he takes into his brain-attic. He will have nothing but the tools which may help him in doing his work, but of these he has a large assortment, and all in the most perfect order. It is a mistake to think that that little room has elastic walls and can distend to any extent. Depend upon it there comes a time when for every addition of knowledge you forget something that you knew before. It is of the highest importance, therefore, not to have useless facts elbowing out the useful ones.\u201d</p> <p>\u2015 Arthur Conan Doyle, A Study in Scarlet</p> <p>  Source: Wikipedia - public domain - 1887</p>"},{"location":"#contributors","title":"Contributors","text":"<ul> <li>@sentenza</li> </ul>"},{"location":"category_theory/","title":"Category Theory","text":"<p>A category is a purely algebraic structure consisting of \"objects\" and \"arrows\" (morphisms) that connect those objects, much like a directed graph with nodes and edges between them. A category will have objects like <code>X</code>, <code>Y</code>, <code>Z</code>,etc. and arrows between objects. Importantly, arrows compose. Given an arrow f \u00a0from <code>X</code> to <code>Y</code>, and another arrow g from <code>Y</code> to <code>Z</code>, their composition is an arrow from <code>X</code> to <code>Z</code>. There is also an identity arrow from every object to itself.</p>"},{"location":"category_theory/#summoner","title":"Summoner","text":"<pre><code>trait Summoner[D[_[_]]] {\ndef apply[C[_]: D]: D[C] = implicitly[D[C]]\n}\n</code></pre> <p>Implicitly</p> <p>The scala Standard library provides a generic type class interface called <code>implicitly</code></p> <pre><code>def implicitly[A](implicit value: A): A = value\n</code></pre> <p>Thus, we can simply use implicitly to summon any value from implicit scope. We have to just provide the right type to implicitly. What is more, we can take advantage of implicitly to test implicit calls that we can't tell for sure if in the current scope or not.  </p>"},{"location":"category_theory/#functor","title":"Functor","text":"<p>The real objective of a Functor is to lift a regular function. Therefore, we can think of a Functor as a trait which has the ability to \"lift\" an arrow that goes from <code>A</code> to <code>B</code> to another arrow that goes from <code>C[A]</code> to <code>C[B]</code>.</p> <pre><code>/** Bro, Do You Even Lift? */\ntrait SortOfFunctor[C[_]] {\ndef lift1[A, B](ab: A =&gt; B): (C[A] =&gt; C[B])\n// If we uncurry lift() we can rewrite it as:\ndef lift2[A, B](ab: A =&gt; B)(ca: C[A]): C[B]\n}\n</code></pre> <p>And now looking at <code>lift2()</code> we can transform it into something that we already know quite well: <code>map()</code>. And, most importantly, Functor is just a type constructor for which <code>map</code> can be implemented:</p> <pre><code>trait Functor[C[_]] {\ndef map[A, B](ca: C[A])(ab: A =&gt; B): C[B]\n}\n\nobject Functor extends Summoner[Functor]\n// Without using a Summoner we would have had:\n// object Functor {\n//   def apply[C[_]: Functor]: Functor[C] = implicitly[Functor[C]]\n// }\n</code></pre> <p>Quote</p> <p>Any type <code>F</code> with a function like <code>map()</code> is a Functor, with one additional restriction: the map function has to preserve the \"structure\" of the value it's mapping over. Thus <code>map(x)</code> preserves the structure of <code>x</code>, mofifying only the elements contained within, while the shape of the structure itself is left intact.</p> <p>And now we can simply rewrite our initial lifting function using <code>map()</code>:</p> <pre><code>def lift(f: A =&gt; B): (F[A] =&gt; F[B]) = _ map f\n</code></pre> <p>Visually, the previous operation could be represented by the following diagram (source):</p> <p></p> <p>Category Theory - Laws</p> <p>In category theory, functors take the objects and morphisms of a category and map them to a different category. By definition, this new category must have an identity and the ability to compose morphisms, but we don't have to check that because the following laws must hold.</p> <p><pre><code>// identity\nmap(id) === id\n\n// composition\ncompose(map(f), map(g)) === map(compose(f, g))\n</code></pre> As stated befone, we can think of a category as a network of objects with morphisms that connect them. So a functor would map one category to the other without breaking the network. </p>"},{"location":"category_theory/#monoid","title":"Monoid","text":"<p>In category theory, a monoid is a category with one object.</p> <p>The Monoid is essentially the first purely algebraic data structure. This kind of algebraic data structures are the corner stone of the technique that gives us a ability to write polymorphic functions. A Monoid is made of:</p> <ul> <li>A type <code>T</code> </li> <li>A binary operation, which is associative, that takes two values of type <code>T</code> and combines them into one</li> <li>A value <code>zero: T</code> which is an identity for the associative operation</li> </ul> <pre><code>trait Monoid[T] {\n// associativity\n// op(op(x, y), z) == op(x, op(y, z))\ndef op(x: T, y: T): T\n\n// identity\n// op(x, zero) == op(zero, x) == x\ndef zero: T\n}\n\n// example\nval stringMonoid = new Monoid[String] {\noverride def op(x: String, y: String): String = x + y\noverride def zero: String = \"\"\n}\n</code></pre>"},{"location":"category_theory/#monad","title":"Monad","text":"<p>The primary purpose of Monads is to let you compose code in for expressions (binding - i.e. to glue code together). Monads are like wrappers that provide us with two fundamental operations:</p> <ul> <li>identity (that we refer as unit in Scala - or pure)</li> <li>bind (flatMap in Scala)</li> </ul> <p>Why do we need monads?</p> <ul> <li>We want to have the ability to use a boxing type (<code>F[_]</code> - <code>Option[String]</code>), mainly because a function should return just one type and, for example, we have to attach a log message to the output value of a function</li> <li>At the same time we'd like to consume our new boxing types without changing our preexistent code. Solution: let's have a special function to \"connect\"/\"compose\"/\"link\" functions. That way, we can, behind the scenes, adapt the output of one function to feed the following one.</li> <li><code>g.flatMap(f)</code> (connect/compose <code>g</code> to <code>f</code> ). We want <code>flatMap</code> to get <code>g</code> 's output, inspect it and, in case it is <code>None</code> just don't call <code>f</code> and return <code>None</code>; or on the contrary, extract the boxed value and feed <code>f</code> with it.</li> <li>Many other problems arise which can be solved using this same pattern: 1. Use a \"box\" to codify/store different meanings/values, and have functions like <code>g</code> that return those \"boxed values\".</li> <li>Remarkable problems that can be solved using this technique are: <ul> <li>having a global state that every function in the sequence of functions (\"the program\") can share: solution <code>State</code> Monad.</li> <li>We don't like \"impure functions\": functions that yield different output for same input. Therefore, let's mark those functions, making them to return a tagged/boxed value: <code>IO</code> monad.</li> <li>let the log of an operation be attached to the value that comes out from a computation: solution <code>Writer</code> Monad.</li> </ul> </li> </ul> <p>https://stackoverflow.com/a/28135478/1977778</p>"},{"location":"category_theory/#review-for-comprehensions","title":"Review For-Comprehensions","text":"<p>As we stated while introducing Monads for expressions have a very deep correllation with this category. That's mainly because a for-comprehension is syntactic sugar for <code>map</code>, <code>flatMap</code> and <code>filter</code> operations on collections.</p> <p>The general form is <code>for (s) yield e</code></p> <ul> <li><code>s</code> is a sequence of generators and filters</li> <li><code>p &lt;- e</code> is a generator</li> <li><code>if f</code> is a filter</li> <li>If there are several generators (equivalent of a nested loop), the last generator varies faster than the first</li> <li>You can use <code>{ s }</code> instead of <code>( s )</code> if you want to use multiple lines without requiring semicolons</li> <li><code>e</code> is an element of the resulting collection</li> </ul> <p>Example 1 <pre><code>    // list all combinations of numbers x and y where x is drawn from\n// 1 to M and y is drawn from 1 to N\nfor (x &lt;- 1 to M; y &lt;- 1 to N)\nyield (x,y)\n</code></pre></p> <p>is equivalent to <pre><code>    (1 to M) flatMap (x =&gt; (1 to N) map (y =&gt; (x, y)))\n</code></pre></p> <p>Translation Rules</p> <p>A for-expression looks like a traditional for loop but works differently internally</p> <p><code>for (x &lt;- e1) yield e2</code> is translated to <code>e1.map(x =&gt; e2)</code></p> <p><code>for (x &lt;- e1 if f) yield e2</code> is translated to <code>for (x &lt;- e1.filter(x =&gt; f)) yield e2</code></p> <p><code>for (x &lt;- e1; y &lt;- e2) yield e3</code> is translated to <code>e1.flatMap(x =&gt; for (y &lt;- e2) yield e3)</code></p> <p>This means you can use a for-comprehension for your own type, as long as you define <code>map</code>, <code>flatMap</code> and <code>filter</code>.</p> <p>Example 2 <pre><code>    for {  i &lt;- 1 until n  j &lt;- 1 until i  if isPrime(i + j)  } yield (i, j)  </code></pre></p> <p>is equivalent to <pre><code>    for (i &lt;- 1 until n; j &lt;- 1 until i if isPrime(i + j))\nyield (i, j)  </code></pre></p> <p>is equivalent to <pre><code>    (1 until n).flatMap(i =&gt; (1 until i).filter(j =&gt; isPrime(i + j)).map(j =&gt; (i, j)))\n</code></pre></p> <p>On flatMap</p> <p> <pre><code>        map with T =&gt; M[R]                  flatten\nM[T]  -------------------------&gt;  M[M[R]]  -----------&gt; M[R]\n</code></pre></p>"},{"location":"category_theory/#defining-monads","title":"Defining Monads","text":"<p>In order to define a Monad in Scala we need <code>map()</code>, <code>flatMap()</code> and a lifting method called <code>unit</code>. As we've already seen in the definition of Functors we could lift a value just using <code>map()</code>. But if we have to simply wrap an object into a new boxing type or wrapper <code>F[_]</code> we can define a new function that we call <code>unit()</code>, which is defined as follows:</p> <pre><code>def unit[A](a: =&gt; A): F[A]\n</code></pre> <p>Now, while observing very carefully that function we can compare it to what the <code>apply</code> method does already in the definition of a new object:</p> <pre><code>// We define a generic Wrapper class\nclass Wrapper[A] private (value: A) { ... }\n// Then we create a companion object which will also be shipped with a factory method that will create a new Wrapper for us\nobject Wrapper {\ndef apply[A](value: A): Wrapper[A] = new Wrapper(value)\n// Using apply() we're actually lifting A to Wrapper[A]\n}\n</code></pre> <p>Basically, we created a new type Wrapper and then we attached to it a companion object that will give us the ability to create new wrappers using <code>val w = Wrapper(value1)</code> using a factory method. Now let's define the body of the <code>Wrapper</code> class, keeping in mind that in order to use for expressions over this class we need <code>map()</code> and <code>flatMap()</code>.</p> <pre><code>class Wrapper[A] private (value: A) {\ndef map[B](f: A =&gt; B): Wrapper[B] = Wrapper(f(value))\n\ndef flatMap[B](f: A =&gt; Wrapper[B]): Wrapper[B] = f(value) }\n// The Companion\nobject Wrapper {\ndef apply[A](value: A): Wrapper[A] = new Wrapper(value)\n}\n</code></pre> <p>Monads in Category Theory</p> <p>In Category Theory, a Monad is a Functor equipped with a pair of \"natural transformations\" satisfying the laws of associativity and identity.</p> <p>OK, now we have all the lego blocks that we actually need to define a Monad in Scala. Note that we define a Monad as a trait and that we extends Functor. Moreover, we add <code>unit()</code> defining it as <code>pure()</code> and then we override <code>map()</code>, which is already defined in Functor, but in this case we take advantage of <code>unit()</code> to lift a value to the boxing type. Also, we redefine <code>map()</code> using <code>flatMap()</code>. </p> <pre><code>trait Monad[C[_]] extends Functor[C] {\n\ndef pure[A](a: =&gt; A): C[A]\n@inline def unit[A](a: =&gt; A): C[A] = pure(a)\n@inline def point[A](a: =&gt; A): C[A] = pure(a)\n\noverride def map[A, B](ca: C[A])(ab: A =&gt; B): C[B] = flatMap(ca)(a =&gt; pure(ab(a)))\n\n// We needed this helper method to compose functions\n// def helper[A, B](ca: C[A], acb: A =&gt; C[B]): C[B] // From Helper to FlatMap\ndef flatMap[A, B](ca: C[A])(acb: A =&gt; C[B]): C[B] // Curried version of helper method\n// haskell bind\n@inline def bind[A, B](ca: C[A])(acb: A =&gt; C[B]): C[B] = flatMap(ca)(acb)\n@inline def &gt;&gt;=[A, B](ca: C[A])(acb: A =&gt; C[B]): C[B]  = flatMap(ca)(acb) // &gt;&gt;= Haskell Logo\n}\n\n// Monad Type class - remember that Summoner defines an apply method\n// that corresponds to unit.\nobject Monad extends Summoner[Monad]\n\n// extending Summoner is the same as \n// object Monad { def apply[C[_]: Monad]: Monad[C] = implicitly[Monad[C]] }\n}\n</code></pre> <p>As you might have supposed <code>unit[MyType](x)</code> performs the wrapping into a <code>Monad[MyType]</code> . It's pretty clear that we defined the method <code>unit()</code> outside the trait body because we don\u2019t want to invoke it upon the existing monadic object.</p> <p>Monad laws</p> <p>If we have some basic value <code>x</code> , a monad instance <code>m</code> (holding some value) and functions <code>f</code> and <code>g</code> of type  <code>Int \u2192 M[Int]</code> , we can write the laws as follows:</p> <ul> <li>left-identity law: <code>unit(x).flatMap(f) == f(x)</code></li> <li>right-identity law: <code>m.flatMap(unit) == m</code></li> <li>associativity law: <code>m.flatMap(f).flatMap(g) == m.flatMap(x \u21d2 f(x).flatMap(g))</code></li> </ul> <p>The only correct definition of Monad</p> <p>A monad is an implementation of one of the minimal sets of monadic combinators, satisfying the laws of associativity and identity.</p>"},{"location":"category_theory/#links","title":"Links","text":"<ul> <li>Demystifying the monad in Scala</li> </ul>"},{"location":"grpc/","title":"gRPC","text":""},{"location":"grpc/#a-step-back-httprest","title":"A step back: HTTP/REST","text":"<p>REST is simple and very easy to use. REST is great for browser. Easy to test our APIs. Developers love this. So we always use REST style to expose our microservices to third-party actors. However it has following issues.</p> <ul> <li>HTTP/1.1 is textual &amp; Heavy. Microservices exchange information by using huge JSON payload.</li> <li>HTTP is stateless. So additional information is sent via headers which are not compressed.</li> <li>HTTP/1.1 is unary \u2013 that is \u2013 you send a request and get a response. You can not send another request until you receive the response.</li> <li>HTTP request requires a 3 way message exchange to set up a TCP connection first which is time consuming.</li> </ul> <p>This all can affect the overall performances of our Microservices. REST is good between browser and back-end. But we need something better than REST for inter microservices communication to avoid above mentioned issues.</p>"},{"location":"grpc/#rpc","title":"RPC","text":"<p>RPC, Remote Procedure Call, is an old mechanism in distributed computing, to execute certain procedure in a remote machine without having to understand the network details. Processes in the same system/different systems which are not sharing the same address space can use RPC for their communication. The call will be made as we would normally invoke a local method call. It follows the client-server model. A client sends a request to the server by invoking a method on the remote server and exchanges messages. RPC provides a well defined interface and type safety.</p> <p></p>"},{"location":"grpc/#what-is-grpc","title":"What is gRPC?","text":"<p>gRPC is a modern, high-performance framework that evolves the age-old remote procedure call (RPC) protocol. At the application level, gRPC streamlines messaging between clients and back-end services. Originating from Google, gRPC is open source and part of the Cloud Native Computing Foundation (CNCF) ecosystem of cloud-native offerings. CNCF considers gRPC an incubating project. Incubating means end users are using the technology in production applications, and the project has a healthy number of contributors.</p> <p>A typical gRPC client app will expose a local, in-process function that implements a business operation. Under the covers, that local function invokes another function on a remote machine. What appears to be a local call essentially becomes a transparent out-of-process call to a remote service. The RPC plumbing abstracts the point-to-point networking communication, serialization, and execution between computers.</p> <p>In cloud-native applications, developers often work across programming languages, frameworks, and technologies. This interoperability complicates message contracts and the plumbing required for cross-platform communication. gRPC provides a \"uniform horizontal layer\" that abstracts these concerns. Developers code in their native platform focused on business functionality, while gRPC handles communication plumbing.</p>"},{"location":"grpc/#please-go-faster","title":"Please, go faster!","text":"<p>It is battle tested for more than a decade. Google site shows they have been processing 10 BILLIONS requests / second using gRPC.</p> <p>gRPC is faster than REST (Checkout this gRPC vs REST Performance Comparison). We achieve this performance gain by switching to gRPC because of these 2 important reasons along with other in-built tools.</p> <ul> <li>HTTP/2</li> <li>Protocol Buffers (Check this out \u2013 Protobuf / Protocol Buffers \u2013 A Simple Introduction)</li> </ul> <p>gRPC by default uses HTTP/2 for transport and Protocol Buffers for message exchange instead of JSON whereas most of the current microservices architectural style is REST with JSON on top of HTTP/1.1</p>"},{"location":"grpc/#when-to-use-grpc","title":"When to use gRPC","text":"<p>Favor gRPC for the following scenarios:</p> <ul> <li>Synchronous backend microservice-to-microservice communication where an immediate response is required to continue processing.</li> <li>Polyglot environments that need to support mixed programming platforms.</li> <li>Low latency and high throughput communication where performance is critical.</li> <li>Point-to-point real-time communication - gRPC can push messages in real time without polling and has excellent support for bi-directional streaming.</li> <li>Network constrained environments \u2013 binary gRPC messages are always smaller than an equivalent text-based JSON message.</li> </ul>"},{"location":"grpc/#protocol-buffers","title":"Protocol buffers","text":"<p>gRPC embraces an open-source technology called Protocol Buffers. They provide a highly efficient and platform-neutral serialization format for serializing structured messages that services send to each other. Using a cross-platform Interface Definition Language (IDL), developers define a service contract for each microservice. The contract, implemented as a text-based <code>.proto</code> file, describes the methods, inputs, and outputs for each service. The same contract file can be used for gRPC clients and services built on different development platforms.</p> <p>Using the proto file, the Protobuf compiler, <code>protoc</code>, generates both client and service code for your target platform. The code includes the following components:</p> <ul> <li>Strongly typed objects, shared by the client and service, that represent the service operations and data elements for a message.</li> <li>A strongly typed base class with the required network plumbing that the remote gRPC service can inherit and extend.</li> <li>A client stub that contains the required plumbing to invoke the remote gRPC service.</li> </ul> <p>At run time, each message is serialized as a standard Protobuf representation and exchanged between the client and remote service. Unlike JSON or XML, Protobuf messages are serialized as compiled binary bytes.</p>"},{"location":"grpc/#optional-fields","title":"Optional fields","text":"<p>For <code>string</code>, <code>bytes</code>, and <code>message</code> fields, <code>optional</code> is compatible with <code>repeated</code>. Given serialized data of a repeated field as input, clients that expect this field to be optional will take the last input value if it's a primitive type field or merge all input elements if it's a message type field. Note that this is not generally safe for numeric types, including bools and enums. Repeated fields of numeric types can be serialized in the packed format, which will not be parsed correctly when an optional field is expected.</p> <p>Since protobuf release 3.15, proto3 supports using the <code>optional</code> keyword (just as in proto2) to give a scalar field presence information.</p> <pre><code>    syntax = \"proto3\";\n\nmessage Foo {\nint32 bar = 1;\noptional int32 baz = 2;\n}\n</code></pre> <p>A <code>has_baz()</code>/<code>hasBaz()</code> method is generated for the <code>optional</code> field above, just as it was in proto2.</p> <p>Under the hood, protoc effectively treats an <code>optional</code> field as if it were declared using a <code>oneof</code> wrapper, as CyberSnoopy\u2019s answer suggested:</p> <pre><code>    message Foo {\nint32 bar = 1;\noneof optional_baz {\nint32 baz = 2;\n}\n}\n</code></pre> <p>If you\u2019ve already used that approach, you can now simplify your message declarations (switch from <code>oneof</code> to <code>optional</code>) and code, since the wire format is the same.</p> <p>The nitty-gritty details about field presence and <code>optional</code> in proto3 can be found in the Application note: Field presence doc.</p> <p>Historical note: Experimental support for <code>optional</code> in proto3 was first announced on Apr 23, 2020 in this comment. Using it required passing protoc the <code>--experimental_allow_proto3_optional</code> flag in releases 3.12-3.14.</p>"},{"location":"grpc/#required-fields","title":"Required fields","text":"<p>We dropped required fields in proto3 because required fields are generally considered harmful and violating protobuf's compatibility semantics. The whole idea of using protobuf is that it allows you to add/remove fields from your protocol definition while still being fully forward/backward compatible with newer/older binaries. Required fields break this though. You can never safely add a required field to a .proto definition, nor can you safely remove an existing required field because both of these actions break wire compatibility. For example, if you add a required field to a .proto definition, binaries built with the new definition won't be able to parse data serialized using the old definition because the required field is not present in old data. In a complex system where .proto definitions are shared widely across many different components of the system, adding/removing required fields could easily bring down multiple parts of the system. We have seen production issues caused by this multiple times and it's pretty much banned everywhere inside Google for anyone to add/remove required fields. For this reason we completely removed required fields in proto3.</p> <p>Proto3 overall seems to favor simplicity, and required removal is simpler. But maybe more convincing, removing required made sense for proto3 when combined with other features, like removal of field presence for primitives and removal of overriding default values.</p> <p>https://stackoverflow.com/a/31814967/1977778</p>"},{"location":"grpc/#types-and-errors","title":"Types and errors","text":"<ul> <li>If you want to raise errors, the minimal bound you need is <code>ApplicativeError</code></li> <li>if you wanna <code>flatMap</code> around, you need to at least use <code>MonadError</code></li> <li>If you need to suspend actions you need to raise this to <code>Sync</code></li> <li> <p>if you need to work with callback-based APIs, you'll need <code>Async</code></p> </li> <li> <p>https://typelevel.org/cats-effect/docs/typeclasses</p> </li> <li>http://typelevel.org/cats/typeclasses/applicativemonaderror.html</li> </ul> <p>If we stick to <code>Async</code>to handle errors properly we have to do something like:</p> <pre><code>    if (request.uid.isBlank || request.uid.isEmpty) {\nAsync[F].raiseError(\nStatus.INVALID_ARGUMENT\n.augmentDescription(\"You have to provide a valid `uid`. It cannot be blank or empty\")\n.asRuntimeException()\n)\n} else ...\n</code></pre> <ul> <li>https://avi.im/grpc-errors/#scala</li> <li>https://github.com/avinassh/grpc-errors/blob/master/scala/src/main/scala/hello/client/HelloClient.scala</li> </ul>"},{"location":"grpc/#scala-play-and-grpc","title":"Scala Play and gRPC","text":"<p>Alternative to <code>fs2-grpc</code> for Scala Play is based on Akka gRPC:</p> <ol> <li>https://doc.akka.io/docs/akka-grpc/current/client/walkthrough.html</li> <li>https://developer.lightbend.com/docs/play-grpc/0.5.0/consuming-grpc.html</li> </ol>"},{"location":"grpc/#play-grpc-sample-project","title":"Play gRPC sample project","text":"<ul> <li> https://github.com/playframework/play-samples/tree/2.8.x/play-scala-grpc-example</li> <li>https://developer.lightbend.com/guides/play-scala-grpc-example/code-details.html</li> <li>https://github.com/akka/akka-grpc (https://doc.akka.io/docs/akka-grpc/current/client/walkthrough.html)</li> <li>https://developer.lightbend.com/docs/play-grpc/current/ (https://github.com/playframework/play-grpc)</li> <li>https://github.com/alexromanov/client-grpc-sample</li> </ul> <p>https://developer.lightbend.com/docs/play-grpc/0.5.0/index.html</p>"},{"location":"grpc/#links","title":"Links","text":"<ul> <li>https://grpc.io/docs/what-is-grpc/introduction/</li> <li>https://developers.google.com/protocol-buffers/docs/proto3#json</li> <li>https://developers.google.com/protocol-buffers/docs/style</li> <li>https://grpc.io/docs/what-is-grpc/core-concepts/</li> <li>https://medium.com/expedia-group-tech/introducing-grpc-to-our-hotels-com-platform-part-1-61716af50b13</li> <li>https://medium.com/expedia-group-tech/introducing-grpc-to-our-hotels-com-platform-part-2-8024a1dda0aa</li> <li>https://docs.microsoft.com/en-us/dotnet/architecture/cloud-native/grpc</li> <li>https://www.vinsguru.com/grpc-introduction-guide/</li> <li>ScalaPB https://medium.com/teads-engineering/bring-grpc-payloads-and-domain-models-closer-with-scalapb-transformations-b23a7115d427</li> <li>ScalaPB docs: https://scalapb.github.io/docs/grpc</li> <li>Status codes: https://grpc.github.io/grpc/core/md_doc_statuscodes.html</li> <li>Error handling: https://www.baeldung.com/grpcs-error-handling</li> </ul>"},{"location":"grpc/#tools","title":"Tools","text":"<ul> <li>https://github.com/ktr0731/evans</li> <li>GUI =&gt; https://github.com/bloomrpc/bloomrpc</li> </ul>"},{"location":"kubernetes/","title":"Kubernetes","text":"<p>So Kubernetes is pronounced /koo-ber-nay'-tace/ and means \"sailing master\"</p> <p>Via @francesc</p>"},{"location":"kubernetes/#terminology","title":"Terminology","text":"<ul> <li>Node: A single virtual or physical machine in a Kubernetes cluster.</li> <li>Cluster: A group of nodes firewalled from the internet, that are the primary compute resources managed by Kubernetes.</li> <li>Edge router: A router that enforces the firewall policy for your cluster. This could be a gateway managed by a cloud provider or a physical piece of hardware.</li> <li>Cluster network: A set of links, logical or physical, that facilitate communication within a cluster according to the Kubernetes networking model. Examples of a Cluster network include Overlays such as flannel or SDNs such as OVS.</li> <li>Service: A Kubernetes Service that identifies a set of pods using label selectors. Unless mentioned otherwise, Services are assumed to have virtual IPs only routable within the cluster network.</li> </ul>"},{"location":"kubernetes/#what-is-a-pod","title":"What is a pod??","text":"<p>A pod is a group of one or more containers (such as Docker containers), with shared storage/network, and a specification for how to run the containers. A pod\u2019s contents are always co-located and co-scheduled, and run in a shared context.</p> <p>Containers within a pod share an IP address and port space, and can find each other via localhost. They can also communicate with each other using standard inter-process communications like SystemV semaphores or POSIX shared memory. Containers in different pods have distinct IP addresses and can not communicate by IPC without special configuration. These containers usually communicate with each other via Pod IP addresses.</p> <p>In terms of Docker constructs, a pod is modelled as a group of Docker containers with shared namespaces and shared volumes.</p>"},{"location":"kubernetes/#kubernetes-plugins","title":"Kubernetes \"plugins\"","text":"<ul> <li>Helm Tiller: Helm is a package manager for Kubernetes and is required to install all the other applications. It is installed in its own pod inside the cluster which can run the <code>helm</code> CLI in a safe environment.</li> <li>Ingress: Ingress can provide load balancing, SSL termination, and name-based virtual hosting. It acts as a web proxy for your applications and is useful if you want to use Auto DevOps or deploy your own web apps.</li> <li>Prometheus: Prometheus is an open-source monitoring and alerting system useful to supervise your deployed applications.</li> </ul>"},{"location":"kubernetes/#how-to-manage-the-google-kubernetes-engine","title":"How to manage the Google Kubernetes Engine","text":"<p>The first step is to check the defined clusters [using the Google Cloud Platform console][gcp-console]. The most common target is, at first, to build and push a containarised application, which means that we start creating a new docker image in our machine, then after checking it locally, we push the image to a docker container registry. </p> <p>Using GCP all these operations can be done by using a mix of <code>docker</code>, <code>gcloud</code> and <code>kubectl</code> commands. First things first, we must create one or more images using the instructions provided here. After that, one can follow the instructions of this gcloud tutorial.</p>"},{"location":"kubernetes/#setting-a-static-ip-and-a-custom-domain-for-the-application","title":"Setting a static IP and a custom domain for the application","text":"<p>In our case we can assign a static IP address for the service created one step above. The best way to achieve this, IMHO, is the web interface and precisely here. </p>"},{"location":"kubernetes/#update-the-image-used-for-the-current-kubernetes-pod","title":"Update the image used for the current Kubernetes POD","text":"<ol> <li> <p>Build a new snapshot optimized for production <code>ng build --prod</code></p> </li> <li> <p>Create a new image and tag it with a new version</p> </li> <li> <p>Test the new image locally</p> </li> <li> <p>Push the newly created image to the container registry</p> </li> </ol> <p>To update the deployed container we can use the set command: <code>kubectl set image deployment/together-rx ...</code></p> <p>Problem: A frequent question that comes up on Slack and Stack Overflow is how to trigger an update to a Deployment/RS/RC when the image tag hasn't changed but the underlying image has.</p> <p>Consider:</p> <ol> <li>There is an existing Deployment with image <code>foo:latest</code></li> <li>User builds a new image <code>foo:latest</code></li> <li>User pushes <code>foo:latest</code> to their registry</li> <li>User wants to do something here to tell the Deployment to pull the new image and do a rolling-update of existing pods</li> </ol> <p>Possible solution for our current scenario: you are using <code>'latest'</code> for testing (this is the \"no sed\" use case), in this case, downtime is fine, and indeed the right approach is likely to completely blow away your stack and redeploy from scratch to get a clean run (=&gt; <code>kubectl set &lt;...&gt;</code>).</p> <p>Keep reading here.</p>"},{"location":"kubernetes/#delete-a-kubernetes-service","title":"Delete a Kubernetes service","text":"<p>To stop and delete a Kubernetes instance/service corresponding to the image we created and then exposed we should instruct Kubernetes to tell the Load Balancer to delete the provisioned service with a simple command like that:</p> <p><code>kubectl delete service container-1</code></p> <p>NOTE: The load balancer is deleted asynchronously in the background when you run <code>kubectl delete</code>. Wait until the load balancer is deleted by watching the output of the following command:</p> <p><code>gcloud compute forwarding-rules list</code></p>"},{"location":"kubernetes/#storage-and-dbs-on-gke","title":"Storage and DBs on GKE","text":"<ul> <li> <p>High Availability PostgreSQL and Kubernetes with Google Cloud</p> </li> <li> <p>How to pronounce Kubernetes</p> </li> </ul>"},{"location":"links/","title":"Links and external resources","text":""},{"location":"links/#functional-programming","title":"Functional Programming","text":"<ul> <li>Category Theory for Programmers</li> <li>Functional Programming For The Rest of Us</li> <li>Parallelism and concurrency need different tools</li> <li>What the Heck are Algebraic Data Types? by Daniel Eklund</li> <li>Functors, Applicatives, And Monads In Pictures</li> <li>A practical introduction to functional programming</li> <li>Functional Programming Basics by Robert C. Martin (Uncle Bob)</li> <li>The Downfall of Imperative Programming</li> </ul>"},{"location":"links/#fp-papers","title":"FP Papers","text":"<ul> <li>Why Functional Programming Matters (J. Hughes The University, Glasgow, 1990)</li> <li>Monoids: Theme and Variations (B. Yorgey, 2012)</li> <li>The Essence of the Iterator Pattern (J. Gibbons and B. Oliveira, Oxford University Computing Laboratory)</li> <li>Applicative programming with effects (C. McBride, University of Nottingham - R. Paterson, City University, London)</li> <li>Stack Safety for Free (Phil Freeman, 2015)</li> <li>Stackless Scala With Free Monads (R\u00fanar \u00d3li Bjarnason)</li> <li>Type Classes as Objects and Implicits (B. Oliveira, A. Moors, M. Odersky)</li> </ul>"},{"location":"links/#scala","title":"Scala","text":""},{"location":"links/#books","title":"Books","text":"<ul> <li>Programming in Scala (2016) by Martin Odersky, Lex Spoon, and Bill Venners</li> <li>Functional Programming in Scala (2014) by Paul Chiusano and Runar Bjarnason (The **Red Book**)</li> <li>A companion booklet to \"Functional Programming in Scala\" (PDF) by R\u00fanar \u00d3li Bjarnason</li> <li>Functional Programming, Simplified (2017) by Alvin Alexander</li> <li>Functional Programming for Mortals with Scalaz (2018) by Sam Halliday </li> <li>Scala with Cats</li> <li>The Type Astronaut's Guide to Shapeless</li> </ul>"},{"location":"links/#readings","title":"Readings","text":"<ul> <li>Scala's Types of Types</li> <li>Typeclasses in scala - Illustrated with cats</li> <li>Algebraic Data Types in Scala by Alvin Alexander</li> <li>More on Sealed Traits in Scala</li> <li>Generalized type constraints in Scala (without a PhD)</li> <li>First steps with monads in Scala</li> <li>Demystifying the Monad in Scala</li> <li>Stackless Scala</li> <li>Rethinking MonadError</li> <li>Free monads - what? and why?</li> <li>Free Monad examples</li> </ul>"},{"location":"links/#cats-and-shapeless","title":"Cats and Shapeless","text":"<ul> <li>Scala Cats library for dummies</li> <li>Cats Infographic</li> <li>Overview of free monad in Cats</li> <li>An IO monad for Cats</li> <li>ScalaFP: Firsthand With Scala-Cats</li> <li>Shapeless for Mortals (2015) by Sam Halliday (Talk)</li> </ul>"},{"location":"links/#haskell-and-ocaml","title":"Haskell and OCaml","text":"<ul> <li>Learn You a Haskell for Great Good!</li> <li>A Quick Tour of Haskell Syntax</li> <li>OCaml taste</li> </ul>"},{"location":"scala/","title":"Scala","text":""},{"location":"scala/#evaluation-rules","title":"Evaluation rules","text":"<ul> <li><code>def</code> defines a method</li> <li><code>val</code> defines a fixed value, it is immmutable and eagerly initialized</li> <li><code>var</code> defines a variable reference, it is mutable and it should be avoided</li> <li><code>lazy</code> only initialised when required and as late as possible (deferred evaluation), default is strict and is not recomputed like by-name parameters</li> </ul> <pre><code>def myFunction = 2         // evaluated when called\nval myImmutableValue = 2   // evaluated immediately\nlazy val iMLazy = 2        // evaluated once when needed\n\ndef sort(x: List[Double])       // call by value\ndef sort(x: =&gt; List[Double])    // call by name\n// ds is a sequence of Double, containing a varying number of arguments\ndef varargsFunction(ds: Double*) = ???\n</code></pre> <ul> <li>Call by-value: evaluates the function arguments before calling the function</li> <li>Call by-name: evaluates the function first, and then evaluates the arguments if need be (each time the parameter is referenced inside the function)</li> </ul>"},{"location":"scala/#type-parameters","title":"Type Parameters","text":"<p>Conceptually similar to C++ templates or Java generics. These can apply to classes, traits or functions.</p> <p><pre><code>class TypedClass[F](arg1: F) { ??? }  new TypedClass[Int](1)  new TypedClass(1)   // the type is being inferred, i.e. determined based on the value arguments  \n</code></pre> Conventionally, the type parameters are expressed using uppercase letters (e.g. A, B, T, F). It's also possible to restrict the type being used, e.g.</p> <pre><code>def func[T &lt;: TopLevel](arg: T): T = { ... } // T must derive from TopLevel or be TopLevel\ndef func[T &gt;: Level1](arg: T): T = { ... }   // T must be a supertype of Level1\ndef func[T &gt;: Level1 &lt;: Top Level](arg: T): T = { ... }\n</code></pre>"},{"location":"scala/#variance","title":"Variance","text":"<p>Quote</p> <p>Variance being a tricky business, users usually get it wrong, and they come away thinking that wildcard and generics are overly complicated. With definition-side variance, you express your intent to the compiler, and the compiler will double check that the methods you want available will indeed be available.</p> <p>- Programming in Scala</p> <p>Upper Bounds: <code>[S &lt;: T]</code> means: S is a subtype of T. Let's suppose that T is actually an <code>Iterable</code>, then S could one of <code>Seq</code>, <code>List</code> or <code>Iterable</code>.</p> <p>Lower Bounds: <code>[S &gt;: T]</code> means: S is a supertype of T, or T is a subtype of S. So, if T is a <code>List</code>, S could be one of <code>List</code>, <code>Seq</code>, <code>Iterable</code>, or <code>AnyRef</code>.</p> <p>Mixed Bounds: <code>[S &gt;: T2 &lt;: T1]</code> means: s is any type on interval between T1 and T2. In this case we have basically a mix of the two cases above.</p> <p>Let's consider <code>NonEmpty &lt;: IntSet</code>, then can we infer that <code>List[NonEmpty] &lt;: List[IntSet]</code>? Intuitively, this makes sense: a list of non-empty sets is a special case of a list of arbitrary sets. We call types for which this relationship holds covariant because their subtyping relationship varies with the type parameter. Thus <code>Lists</code> in scala are covariant.</p> <p>Does covariance make sense for all types, not just for List? No. For instance, in Scala, arrays are not covariant.</p> <p>When does it make sense to subtype one type with another?</p> <p>It is safe to assume that a type <code>T</code> is a subtype of a type <code>U</code> (<code>T &lt;: U</code>) if you can substitute a value of type <code>T</code> wherever a value of type U is required. This is called the Liskov Substitution Principle.</p> <p>Liskov Substitution Principle</p> <p> https://twitter.com/javi/status/1004821965868109824</p> <p>Say <code>C[T]</code> is a parameterized type, and A, B are types such that:</p> <ul> <li>Given <code>A &lt;: B</code> (A is a subtype of B)</li> <li>If <code>C[A] &lt;: C[B]</code>, <code>C</code> is covariant</li> <li>If <code>C[A] &gt;: C[B]</code>, <code>C</code> is contravariant</li> <li>Neither <code>C[A]</code> or <code>C[B]</code> is a subtype of the other, then C is invariant (or \"nonvariant\"). </li> </ul> <p>Scala lets you declare the variance of a type by annotating the type parameter:</p> <pre><code>class C[+A] { ... } // C is covariant\nclass C[-A] { ... } // C is contravariant\nclass C[A]  { ... } // C is invariant\n</code></pre> <p>So, given that <code>Any</code> &gt; <code>AnyRef</code> &gt; <code>IntSet</code> &gt; <code>Empty</code> and <code>NonEmpty</code>, if  <pre><code>type A = IntSet =&gt; NonEmpty\ntype B = NonEmpty =&gt; IntSet\n</code></pre> According to the Liskov Principle =&gt; <code>A &lt;: B</code>, since B can return an Empty or NonEmpty, but A can return only NonEmpty.</p> <p>For a function, if <code>A2 &lt;: A1</code> and <code>B1 &lt;: B2</code>, then <code>A1 =&gt; B1 &lt;: A2 =&gt; B2</code>. The consequence is that functions must be contravariant in their argument types and covariant in their result types.</p> <pre><code>/** The Scala Function1 S =&gt; T */\ntrait Function1[-S, +T] {\n// S is contravariant, while T is covariant\ndef apply(x: S): T\n}\n</code></pre> <p>This example shows that functions are contravariant in argument types and covariant in return types.</p> <pre><code>package io.github.sentenza.cars\n\nclass Car {}\nclass SportsCar extends Car {}\nclass Ferrari extends SportsCar {}\n\nobject morecovariance extends App {\n\n// Test 1: Works as expected\n\ndef test1( arg: SportsCar =&gt; SportsCar ) = {\nnew SportsCar\n}\n\ndef foo1(arg: Car): Ferrari = { new Ferrari }\ndef foo2(arg: SportsCar): Car = { new Ferrari }\ndef foo3(arg: Ferrari): Ferrari = { new Ferrari }\n\ntest1(foo1) // compiles\ntest1(foo2) // Fails due to wrong return type. \ntest1(foo3) // Fails due to wrong parameter type\n\n}\n</code></pre> <p>Find out more about variance in Covariance And Contravariance in Scala</p> <p>Type constructor and Variance</p> <p>Abstract</p> <p>To be added</p> <p>pag. 392 of the White Scala Manual</p>"},{"location":"scala/#objects-and-code-organization","title":"Objects and Code organization","text":"<p>Quote</p> <p>Scala has no globally visible methods: every method must be contained in an object or a class. However, using methods named <code>apply</code> inside global objects, you can support usage patterns that look like invocations of global methods.</p> <p>From Programming in Scala - Second edition (by M. Odersky, L. Spoon, B. Venners)</p> <p>As you can read above, I introduced Objects in terms of the functions they contain. It's very important to stress on this aspect, because Classes and Objects should be seen under a different light using Scala, especially if you come from an imperative OOP language, like Java or C++. They are just a way to organise your functions and at some point, using traits, objects (companion objects) and case classes (data constructors) you will eventually be able to build up your coding architecture based on types and composition of functions.</p> <ul> <li>About Case Class</li> </ul>"},{"location":"scala/#general-object-hierarchy","title":"General object hierarchy","text":"<p>Note</p> <p>All members of packages <code>scala</code> and <code>java.lang</code> as well as all members of the object <code>scala.Predef</code> are automatically imported.</p> <ul> <li><code>scala.Nothing</code> is a trait that is the bottom subtype of every subtype of <code>scala.Any</code><ul> <li><code>scala.Any</code> base type of all types. It has methods <code>hashCode</code> and <code>toString</code> that can be overridden</li> </ul> </li> <li><code>scala.AnyVal</code> is the base type of all primitive types: <code>Double</code>, <code>Float</code>, etc.</li> <li><code>scala.AnyRef</code> base type of all reference types. (alias of <code>java.lang.Object</code>, supertype of <code>java.lang.String</code>, <code>scala.List</code>, any user-defined class)</li> <li><code>scala.Null</code> is a subtype of any <code>scala.AnyRef</code>, and <code>scala.Nothing</code> is a subtype of any other type without any instance.<ul> <li><code>Null</code> is a trait and is the bottom type similiar to <code>Nothing</code> but only for <code>AnyRef</code> not <code>AnyVal</code></li> <li><code>null</code> is the only instance of type <code>Null</code></li> </ul> </li> <li><code>Nil</code> is an empty list that is defined as a <code>List[Nothing]</code></li> <li><code>None</code> is an empty option that is defined as a <code>Option[Nothing]</code></li> <li><code>Unit</code> is a subtype of <code>AnyVal</code>, it's only value is <code>()</code> and it is not represented by any object in the underlying runtime system. A method with return type <code>Unit</code> is analogous to a Java method which is declared <code>void</code></li> </ul>"},{"location":"scala/#factory-object","title":"Factory Object","text":"<p>The following example has been taken from Programming in Scala:</p> <pre><code>abstract class Element {\ndef contents: Array[String]\ndef height: Int = contents.length\ndef width: Int = if (height == 0) 0 else contents(0).length\n}\n\nclass ArrayElements(val contents: Array[String]) extends Element // Invoking superclass constructor while extending the class itself\nclass LineElement(s: String) extends ArrayElement(Array(s)) {\noverride def width = s.length // Int is inferred\noverride def width = 1\n}\n\nclass UniformElement(\nch: Char,\noverride val width: Int,\noverride val heigth: Int\n) extends Element {\nprivate val line = ch.toString * width\ndef contents = Array.fill(height)(line)\n}\n</code></pre> <p>Now, what we can do is defining a Factory Object which contains methods that construct other objects, without exposing each class implementation. Basically, we can hide each class inside a Singleton Object, which will represent just a tag for the overloaded methods that will give us the ability to instantiate each subclass dinamically, and using polymorphism at the same time.</p> <p>Important</p> <p>Note that OOP is not a paradigm, but it's just a way to define our code structure in a logic manner that is similar to playing with LEGOs. OOP can be seen like an orthogonal dimension compared to functional, declarative or imperative paradigms.</p> <pre><code>// We start defining a Singleton Object\nobject Element {\n// we can now hide classes as private fields of this object\nprivate class ArrayElements(\nval contents: Array[String]\n) extends Element\n\nprivate class LineElement(s: String) extends Element {\nval contents = Array(s)\noverride def width = s.length\noverride def width = 1\n}\n\nprivate class UniformElement(\nch: Char,\noverride val width: Int,\noverride val heigth: Int\n) extends Element {\nprivate val line = ch.toString * width\ndef contents = Array.fill(height)(line)\n} // FACTORY\ndef elem(contents: Array[String]): Element =\nnew ArrayElement(contents)\n\ndef elem(chr: Char, width: Int, heigth: Int): Element = new UniformElement(chr, width, height)\n\ndef elem(line: String): Elem =\nnew LineElement(line)\n}\n</code></pre> <p>Objects creation are centralized and the details now are hidden. </p> <p>Open/Closed Principle</p> <p>This will eventually give an easy way to understand how to use these elements, and at the same time this small change will give the developer the Open/Closed Principle for free because less detail is exposed.</p> <p>\u201cSoftware entities \u2026 should be open for extension, but closed for modification.\u201d</p> <p>This provides more opportunities to change the implementation of the library without breaking client code. At the same time a class will have a single responsibility, and only one potential change in the software\u2019s specification should be able to affect the specification of the class (Single Responsibility Principle). So, writing <code>SOLID</code> code pays off at the end. </p>"},{"location":"scala/#factory-method","title":"Factory method","text":"<p>In Java you can create a private constructor by making it <code>private</code>. In Scala one can achieve the same behaviour prepending the <code>private</code> modifier to the default constructor. </p> <pre><code>class Point private(coordX: Float, coordY: Float) {\nval x = coordX\nval y = coordY\n\n/** Public auxiliary constructor\n      * Setting the point at the origin of the Cartesian axes\n      * calling the default private constructor using the \n      */ def this() = this(0.0, 0.0)\n\ndef getPoint = (x, y)\n}\n</code></pre> <p>You cannot instantiate a new point using the default constructor:</p> <pre><code>val errorPoint = new Point(45.9, 21.08) // ERROR\nval correctPoint = new Point() // (0.0, 0.0)\n</code></pre> <p>A possible solution to define a new <code>Point</code> is given by the usage of a companion object and a factory method that will give us a convenient way to define a new object, without actually call the <code>new</code> operator. To do so one can add the <code>apply()</code> method to the newly created object, which will have the same acess rights to the <code>Point</code> class if placed in the same file.</p> <p>Therefore, the <code>apply()</code> method will be able to use the private construction of the <code>Point</code> class and then it will become a factory method:</p> <pre><code>class Point[T &lt;: Double] private(coordX: T, coordY: T) { ... }\nobject Point {\ndef apply[T &lt;: Double](x: T, y: T) = new Point[T](x, y)\n}\n</code></pre>"},{"location":"scala/#collections","title":"Collections","text":"<p>Scala defines several collection classes:</p>"},{"location":"scala/#base-classes","title":"Base Classes","text":"<ul> <li><code>Iterable</code> (collections you can iterate on)</li> <li><code>Seq</code> (ordered sequences)</li> <li><code>Set</code></li> <li><code>Map</code> (lookup data structure)</li> </ul>"},{"location":"scala/#immutable-collections","title":"Immutable Collections","text":"<ul> <li><code>List</code> (linked list, provides fast sequential access)</li> <li><code>Stream</code> (same as List, except that the tail is evaluated only on demand)</li> <li><code>Vector</code> (array-like type, implemented as tree of blocks, provides fast random access)</li> <li><code>Range</code> (ordered sequence of integers with equal spacing)</li> <li><code>String</code> (Java type, implicitly converted to a character sequence, so you can treat every string like a <code>Seq[Char]</code>)</li> <li><code>Map</code> (collection that maps keys to values)</li> <li><code>Set</code> (collection without duplicate elements)</li> </ul>"},{"location":"scala/#mutable-collections","title":"Mutable Collections","text":"<ul> <li><code>Array</code> (Scala arrays are native JVM arrays at runtime, therefore they are very performant)</li> <li>Scala also has mutable maps and sets; these should only be used if there are performance issues with immutable types</li> </ul>"},{"location":"scala/#collections-snippet","title":"Collections snippet","text":"<p>Snippet</p> <pre><code>val r: Range = 1 until 5 // 1, 2, 3, 4\nval s: Range = 1 to 5    // 1, 2, 3, 4, 5\n1 to 10 by 3  // 1, 4, 7, 10\n6 to 1 by -2  // 6, 4, 2\n\n// Operations on sequences\nval xs = List(...)\nxs.length   // number of elements, complexity O(n)\nxs.last     // last element (exception if xs is empty), complexity O(n)\nxs.init     // all elements of xs but the last (exception if xs is empty), complexity O(n)\nxs take n   // first n elements of xs\nxs drop n   // the rest of the collection after taking n elements\nxs(n)       // the nth element of xs, complexity O(n)\nxs ++ ys    // concatenation, complexity O(n)\nxs.reverse  // reverse the order, complexity O(n)\nxs updated(n, x)  // same list than xs, except at index n where it contains x, complexity O(n)\nxs indexOf x      // the index of the first element equal to x (-1 otherwise)\nxs contains x     // same as xs indexOf x &gt;= 0\nxs filter p       // returns a list of the elements that satisfy the predicate p\nxs filterNot p    // filter with negated p \nxs partition p    // same as (xs filter p, xs filterNot p)\nxs takeWhile p    // the longest prefix consisting of elements that satisfy p\nxs dropWhile p    // the remainder of the list after any leading element satisfying p have been removed\nxs span p         // same as (xs takeWhile p, xs dropWhile p)\n\nList(x1, ..., xn) reduceLeft op    // (...(x1 op x2) op x3) op ...) op xn\nList(x1, ..., xn).foldLeft(z)(op)  // (...( z op x1) op x2) op ...) op xn\nList(x1, ..., xn) reduceRight op   // x1 op (... (x{n-1} op xn) ...)\nList(x1, ..., xn).foldRight(z)(op) // x1 op (... (    xn op  z) ...)\n\nxs exists p    // true if there is at least one element for which predicate p is true\nxs forall p    // true if p(x) is true for all elements\nxs zip ys      // returns a list of pairs which groups elements with same index together\nxs unzip       // opposite of zip: returns a pair of two lists\nxs.flatMap f   // applies the function to all elements and concatenates the result\nxs.sum         // sum of elements of the numeric collection\nxs.product     // product of elements of the numeric collection\nxs.max         // maximum of collection\nxs.min         // minimum of collection\nxs.flatten     // flattens a collection of collection into a single-level collection\nxs groupBy f   // returns a map which points to a list of elements\nxs distinct    // sequence of distinct entries (removes duplicates)\n\nx +: xs  // creates a new collection with leading element x\nxs :+ x  // creates a new collection with trailing element x\n\n// Operations on maps\nval myMap = Map(\"I\" -&gt; 1, \"V\" -&gt; 5, \"X\" -&gt; 10)  // create a map\nmyMap(\"I\")      // =&gt; 1  \nmyMap(\"A\")      // =&gt; java.util.NoSuchElementException  \nmyMap get \"A\"   // =&gt; None \nmyMap get \"I\"   // =&gt; Some(1)\nmyMap.updated(\"V\", 15)  // returns a new map where \"V\" maps to 15 (entry is updated)\n// if the key (\"V\" here) does not exist, a new entry is added\n\n// Operations on Streams\nval xs = Stream(1, 2, 3)\nval xs = Stream.cons(1, Stream.cons(2, Stream.cons(3, Stream.empty))) // same as above\n(1 to 1000).toStream // =&gt; Stream(1, ?)\nx #:: xs // Same as Stream.cons(x, xs)\n// In the Stream's cons operator, the second parameter (the tail)\n// is defined as a \"call by name\" parameter.\n// Note that x::xs always produces a List\n</code></pre>"},{"location":"scala/#pairs-similar-for-larger-tuples","title":"Pairs (similar for larger Tuples)","text":"<pre><code>    val pair = (\"answer\", 42)   // type: (String, Int)\nval x = (\"x\" -&gt; 90)         // type: (String, Int)\nval y = (\"y\" -&gt; -5)         // type: (String, Int)\nval z = (\"z\" -&gt; 0)          // type: (String, Int)\nval (label, value) = pair   // label = \"answer\", value = 42  \npair._1 // \"answer\"  \npair._2 // 42  \n</code></pre>"},{"location":"scala/#ordering","title":"Ordering","text":"<p>There is already a class in the standard library that represents orderings: <code>scala.math.Ordering[T]</code> which contains comparison functions such as <code>lt()</code> and <code>gt()</code> for standard types. Types with a single natural ordering should inherit from  the trait <code>scala.math.Ordered[T]</code>. <pre><code>import math.Ordering  def msort[T](xs: List[T])(implicit ord: Ordering) = { ...}  msort(fruits)(Ordering.String)  msort(fruits)   // the compiler figures out the right ordering  \n</code></pre></p>"},{"location":"scala/#typeclass","title":"Typeclass","text":"<p>Quote</p> <p>[...] Type class is a class (group) of types, which satisfy some contract defined in a trait with addition that such functionality (trait and implementation) can be added without any changes to the original code. One could say that the same could be achieved by extending a simple trait, but with type classes it is not necessary to predict such a need beforehand.</p> <p>There is no special syntax in Scala to express a type class, but the same functionality can be achieved using constructs that already exist in the language. That\u2019s what makes it a little difficult for newcomers to spot a type class in code. A typical implementation of a type class uses some syntactic sugar as well, which also doesn\u2019t make it clear right away what we are dealing with.</p> <p>https://blog.scalac.io/2017/04/19/typeclasses-in-scala.html</p>"},{"location":"scala/#sbt","title":"SBT","text":"<ul> <li>Defining dependencies and Settins in /project</li> </ul>"}]}